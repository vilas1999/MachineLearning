{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression using SGD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I2S-uFqwSvmg",
        "colab": {}
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUxLkBjISvmr",
        "colab": {}
      },
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xexp5GYNSvmz",
        "outputId": "60f30ef0-2263-4591-f8b9-b6b0a8ec91a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "54vJVc_KSvm9"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pKAn1-ASvm_",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r97pFTgrSvnE",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jykLIXZNSvnJ",
        "outputId": "a81f3ca2-cd71-421b-a072-14321ccb69cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g0-M6oXASvnO"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sShoMeocSvnP",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gm6wi8L2SvnU",
        "outputId": "6c05b60b-b467-4bae-ec05-548ae633b8ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4WFoxgASvnc",
        "outputId": "9e1b83cc-747f-42cb-8121-041f514f5b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "clf.fit(X=X_train, y=y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 10 epochs took 0.08 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WaVxhGpSvnj",
        "outputId": "778f5039-450f-4cf2-a690-945399cf9454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Su9e8fRLSvno"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gcz5_UqCSvnq"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UOBvEchCSvnr"
      },
      "source": [
        "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xbn61rrXSvnt"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "14bA5yR3Svnv"
      },
      "source": [
        "- Load the datasets(train and test) into the respective arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c7183hFBSvnv"
      },
      "source": [
        "- Initialize the weight_vector and intercept term randomly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdLeFU0USvnx"
      },
      "source": [
        "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pEVtAlO1Svny"
      },
      "source": [
        "- for each epoch:\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
        "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
        "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
        "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2qmRH4UpSvny"
      },
      "source": [
        "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lbZf9p5gSvn1"
      },
      "source": [
        "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2ojr2IQEx4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7V0YVv9Ex5J",
        "colab_type": "text"
      },
      "source": [
        "## Initializing W,B,eta0 and alpha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fpz8X5DMSvn2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b3275ef-ea0d-4897-b01f-263c766ee11b"
      },
      "source": [
        "w = np.zeros_like(X_train[0])\n",
        "b = 0\n",
        "eta0  = 0.0001\n",
        "alpha = 0.0001\n",
        "N = len(X_train)\n",
        "N"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIujvyQ1Ex5W",
        "colab_type": "text"
      },
      "source": [
        "### Computing Log-loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2sjDWTKEx5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "# you can free to change all these codes/structure\n",
        "def compute_log_loss(y_train,pred):\n",
        "    sum1 = 0\n",
        "    for i in range(len(pred)):\n",
        "    \n",
        "        sum1 += ((y_train[i] * math.log(pred[i])) + ((1-y_train[i]) * math.log((1-pred[i]))))\n",
        "    \n",
        "    loss = (-sum1/len(y_train))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA91PjbZEx5h",
        "colab_type": "text"
      },
      "source": [
        "### Sigmoid and predict functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k385Iaf7Ex5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "74360c67-5bc9-4983-b61b-73ba27798431"
      },
      "source": [
        "def sigmoid(x,w,b):\n",
        "    return (1/(1+np.exp(-(np.dot(x,w)+b))))\n",
        "\n",
        "def predict(X_train,w,b):\n",
        "    pred = []\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "         pred.append(sigmoid(X_train[i],w,b))\n",
        "    \n",
        "    return pred\n",
        "\n",
        "train_loss = []\n",
        "test_loss  = []\n",
        "\n",
        "#print(pred[:5])\n",
        "train_pred = predict(X_train,w,b)\n",
        "test_pred = predict(X_test,w,b)\n",
        "\n",
        "#Computing log-loss        \n",
        "train_loss.append(compute_log_loss(y_train,train_pred))\n",
        "test_loss.append(compute_log_loss(y_test,test_pred))\n",
        "print(train_loss[0])\n",
        "print(test_loss[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805594285\n",
            "0.6931471805600672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bke7s6e4Ex5q",
        "colab_type": "text"
      },
      "source": [
        "### SGD with train and test loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUEpjwTeEx5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26153701-e4f5-421c-8bea-21f386f33459"
      },
      "source": [
        "import random\n",
        "\n",
        "for epoch in (range(100)):\n",
        "    for i in range(N):\n",
        "        batch = random.randrange(1,N)\n",
        "        \n",
        "        w = (( 1 - ( (alpha*eta0)/N) ) * w ) + ( (alpha*X_train[batch]) * ( y_train[batch] - sigmoid( X_train[batch],w, b) ) )\n",
        "        #w = (1 - ( (alpha * eta0)/N ) * w ) + ( ( alpha * X_train[batch] ) * ( y_train[batch] - sigmoid(X_train[batch],w,b ) ) )\n",
        "        #b = b + (alpha * (y_train[batch] - sigmoid(X_train,w,b))) \n",
        "        b = (b - ( alpha * ( -(y_train[batch]) + sigmoid(X_train[batch],w, b) ) ))\n",
        "\n",
        "    \n",
        "    y_train_ep = predict(X_train,w,b)\n",
        "    y_test_ep = predict(X_test,w,b)\n",
        "    \n",
        "    \n",
        "    train_loss.append(compute_log_loss(y_train,y_train_ep))\n",
        "    test_loss.append(compute_log_loss(y_test,y_test_ep))\n",
        "    \n",
        "    \n",
        "    print(\"Epoch\",epoch,\"train_loss\",train_loss[-1:],'test_loss',test_loss[-1:])\n",
        "        \n",
        "        \n",
        "        \n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 train_loss [0.4037381695280155] test_loss [0.4051409460739654]\n",
            "Epoch 1 train_loss [0.3881853608997544] test_loss [0.3898325942293472]\n",
            "Epoch 2 train_loss [0.3829884680624984] test_loss [0.3850343141489612]\n",
            "Epoch 3 train_loss [0.3810364322337181] test_loss [0.3829650524208779]\n",
            "Epoch 4 train_loss [0.3793307474020105] test_loss [0.3811837756963011]\n",
            "Epoch 5 train_loss [0.37899058749291276] test_loss [0.38093730513735213]\n",
            "Epoch 6 train_loss [0.37860451654347943] test_loss [0.3809161630106351]\n",
            "Epoch 7 train_loss [0.37859248967793074] test_loss [0.3806523284867069]\n",
            "Epoch 8 train_loss [0.37839479771533124] test_loss [0.38062307300682996]\n",
            "Epoch 9 train_loss [0.3785997381435557] test_loss [0.3801598326075643]\n",
            "Epoch 10 train_loss [0.37875586516661724] test_loss [0.3808460189708544]\n",
            "Epoch 11 train_loss [0.3785334950483176] test_loss [0.38043706353596246]\n",
            "Epoch 12 train_loss [0.378319311341773] test_loss [0.38046905269524517]\n",
            "Epoch 13 train_loss [0.37849586907479216] test_loss [0.38106104382028905]\n",
            "Epoch 14 train_loss [0.37844457709883084] test_loss [0.38077869343296433]\n",
            "Epoch 15 train_loss [0.37828723193219166] test_loss [0.38057143966617346]\n",
            "Epoch 16 train_loss [0.3782556257651049] test_loss [0.3802836106482321]\n",
            "Epoch 17 train_loss [0.37828596979548795] test_loss [0.38025606448603394]\n",
            "Epoch 18 train_loss [0.378790052102815] test_loss [0.3806353954847428]\n",
            "Epoch 19 train_loss [0.3785487186734486] test_loss [0.3806716857464192]\n",
            "Epoch 20 train_loss [0.37834039873327374] test_loss [0.380488759085167]\n",
            "Epoch 21 train_loss [0.37856679503859286] test_loss [0.3808323157183337]\n",
            "Epoch 22 train_loss [0.3784557350099683] test_loss [0.3805610330744679]\n",
            "Epoch 23 train_loss [0.3782690945458786] test_loss [0.3801988431722665]\n",
            "Epoch 24 train_loss [0.37833664657542676] test_loss [0.3805911635537753]\n",
            "Epoch 25 train_loss [0.3784389083729466] test_loss [0.3804360786727016]\n",
            "Epoch 26 train_loss [0.3784692967084271] test_loss [0.38015570499625095]\n",
            "Epoch 27 train_loss [0.37841150141590435] test_loss [0.3806889376559375]\n",
            "Epoch 28 train_loss [0.37831904368221814] test_loss [0.38042784510305055]\n",
            "Epoch 29 train_loss [0.37826504783083614] test_loss [0.3801105079157159]\n",
            "Epoch 30 train_loss [0.3784010305318321] test_loss [0.3802748021726142]\n",
            "Epoch 31 train_loss [0.37868579423054605] test_loss [0.3806650095170454]\n",
            "Epoch 32 train_loss [0.37839632632599973] test_loss [0.38008283843529606]\n",
            "Epoch 33 train_loss [0.37860429504902243] test_loss [0.38096074308666156]\n",
            "Epoch 34 train_loss [0.3783298607628876] test_loss [0.3804859460392227]\n",
            "Epoch 35 train_loss [0.37824503502500256] test_loss [0.38015237314926836]\n",
            "Epoch 36 train_loss [0.37879789758874044] test_loss [0.3803794993881466]\n",
            "Epoch 37 train_loss [0.3785472200787773] test_loss [0.38040218673309906]\n",
            "Epoch 38 train_loss [0.37838983389721187] test_loss [0.3802951235580614]\n",
            "Epoch 39 train_loss [0.378407534818248] test_loss [0.38084593052827237]\n",
            "Epoch 40 train_loss [0.37849607363090726] test_loss [0.38018167722818375]\n",
            "Epoch 41 train_loss [0.37887814382749574] test_loss [0.3805813042564888]\n",
            "Epoch 42 train_loss [0.37844404692467415] test_loss [0.38050030006947005]\n",
            "Epoch 43 train_loss [0.3786995542218357] test_loss [0.38059106130396336]\n",
            "Epoch 44 train_loss [0.3782801139447077] test_loss [0.3806497539785946]\n",
            "Epoch 45 train_loss [0.3785891608233322] test_loss [0.3808594095194392]\n",
            "Epoch 46 train_loss [0.37838072581047594] test_loss [0.3804360100608189]\n",
            "Epoch 47 train_loss [0.3781714066728731] test_loss [0.38016317734765137]\n",
            "Epoch 48 train_loss [0.37828268136228665] test_loss [0.38043582085017064]\n",
            "Epoch 49 train_loss [0.3783174939444274] test_loss [0.38047780731136643]\n",
            "Epoch 50 train_loss [0.37842365245193715] test_loss [0.3803371019224976]\n",
            "Epoch 51 train_loss [0.3783860620355435] test_loss [0.3801683995299245]\n",
            "Epoch 52 train_loss [0.37838055985588154] test_loss [0.3803110665815696]\n",
            "Epoch 53 train_loss [0.3783420480114288] test_loss [0.380476787936208]\n",
            "Epoch 54 train_loss [0.37865727386751236] test_loss [0.3804228973577421]\n",
            "Epoch 55 train_loss [0.3782474839632092] test_loss [0.3804848064206839]\n",
            "Epoch 56 train_loss [0.3782923586710222] test_loss [0.3804011586827127]\n",
            "Epoch 57 train_loss [0.378460508474135] test_loss [0.380454314739438]\n",
            "Epoch 58 train_loss [0.3785546435055251] test_loss [0.38099400105225767]\n",
            "Epoch 59 train_loss [0.3783692168838415] test_loss [0.3808645734690277]\n",
            "Epoch 60 train_loss [0.3790874604560089] test_loss [0.38078547195640866]\n",
            "Epoch 61 train_loss [0.378385870247855] test_loss [0.38066898640585073]\n",
            "Epoch 62 train_loss [0.37830267246996796] test_loss [0.38053803311555623]\n",
            "Epoch 63 train_loss [0.37824347026778515] test_loss [0.38021824983708474]\n",
            "Epoch 64 train_loss [0.3784408428316232] test_loss [0.38043835737265297]\n",
            "Epoch 65 train_loss [0.37836581233019456] test_loss [0.38068339216397623]\n",
            "Epoch 66 train_loss [0.37845100227737377] test_loss [0.3807824798604219]\n",
            "Epoch 67 train_loss [0.37847992231806377] test_loss [0.3804682657252031]\n",
            "Epoch 68 train_loss [0.3784411767775674] test_loss [0.38092653904334467]\n",
            "Epoch 69 train_loss [0.3782921860759299] test_loss [0.38020459935435513]\n",
            "Epoch 70 train_loss [0.3785881508556596] test_loss [0.3809583408438084]\n",
            "Epoch 71 train_loss [0.3783378803963715] test_loss [0.3803961820293535]\n",
            "Epoch 72 train_loss [0.37826974638864536] test_loss [0.38034150901414987]\n",
            "Epoch 73 train_loss [0.378530156100854] test_loss [0.3807972266983999]\n",
            "Epoch 74 train_loss [0.37858045151545444] test_loss [0.38051774743326866]\n",
            "Epoch 75 train_loss [0.37820712538405743] test_loss [0.38036716256505965]\n",
            "Epoch 76 train_loss [0.3784912937264594] test_loss [0.38031813672802245]\n",
            "Epoch 77 train_loss [0.3784848584366938] test_loss [0.38055749435134995]\n",
            "Epoch 78 train_loss [0.3783430587083698] test_loss [0.3807588672280358]\n",
            "Epoch 79 train_loss [0.37837175280467616] test_loss [0.38047390286230287]\n",
            "Epoch 80 train_loss [0.3784321673710929] test_loss [0.3807268129664003]\n",
            "Epoch 81 train_loss [0.3788426523451305] test_loss [0.3811161603145213]\n",
            "Epoch 82 train_loss [0.3787392300059855] test_loss [0.3810545793385992]\n",
            "Epoch 83 train_loss [0.37859481559275476] test_loss [0.38074771166607935]\n",
            "Epoch 84 train_loss [0.37836201947462694] test_loss [0.3805159208115878]\n",
            "Epoch 85 train_loss [0.3784248806056946] test_loss [0.3805133354351515]\n",
            "Epoch 86 train_loss [0.3786555140887769] test_loss [0.3814232068641636]\n",
            "Epoch 87 train_loss [0.37863614401627127] test_loss [0.3812271984515548]\n",
            "Epoch 88 train_loss [0.3785168930344105] test_loss [0.38013927520184143]\n",
            "Epoch 89 train_loss [0.3786452168124955] test_loss [0.3808409840228766]\n",
            "Epoch 90 train_loss [0.3786334208030699] test_loss [0.38057041732211777]\n",
            "Epoch 91 train_loss [0.3785733640230413] test_loss [0.38056684276704683]\n",
            "Epoch 92 train_loss [0.3784738321160625] test_loss [0.3809593605655751]\n",
            "Epoch 93 train_loss [0.37839491220362464] test_loss [0.3807692128526246]\n",
            "Epoch 94 train_loss [0.37847350866712937] test_loss [0.38017437066722504]\n",
            "Epoch 95 train_loss [0.3783669260998517] test_loss [0.3805901461418767]\n",
            "Epoch 96 train_loss [0.37831901692810516] test_loss [0.3803873096475521]\n",
            "Epoch 97 train_loss [0.37850949084546265] test_loss [0.38023338233336923]\n",
            "Epoch 98 train_loss [0.3782134534745643] test_loss [0.3802217437863191]\n",
            "Epoch 99 train_loss [0.3784287208870628] test_loss [0.3803246990204749]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91dCQyfjEx51",
        "colab_type": "text"
      },
      "source": [
        "### Plot of train-loss and test-loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ENhRAGEx53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4bdfdfb0-497b-440d-b66d-6f4fea174e1a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plt.figure(figsize=(9,6))\n",
        "\n",
        "plt.plot(train_loss[1:], label=\"train log-loss\")\n",
        "plt.plot(test_loss[1:], label=\"test log-loss\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Log-loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Log-loss\")\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ULdVJ0CEx5_",
        "colab_type": "text"
      },
      "source": [
        "### Weight and intercept "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZI9dbDSEx6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "cd396546-51af-4be9-d4da-2d50bcb0254d"
      },
      "source": [
        "print(\"Weight vector(W) :\",w)\n",
        "print('Intercept(B) :',b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight vector(W) : [-0.43026846  0.19244311 -0.14315103  0.34086735 -0.22428848  0.56679028\n",
            " -0.44654246 -0.09243658  0.22266273  0.17870868  0.20592653 -0.00220059\n",
            " -0.0813303   0.33423687  0.03268197]\n",
            "Intercept(B) : -0.891685729814871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZHKyZJ0Ex6L",
        "colab_type": "text"
      },
      "source": [
        "### Diff btw skcit learn and custom implemented weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yy8jWaa7Svn_",
        "outputId": "7965b0c8-63a6-4386-c2e5-cf3c29b2a544",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.00690154,  0.00696746,  0.00543933, -0.00057672, -0.01610178,\n",
              "          0.0066245 ,  0.00588236,  0.00165155,  0.01338953, -0.00213258,\n",
              "          0.00887463, -0.00641975, -0.0017266 , -0.00429115,  0.01001476]]),\n",
              " array([-0.03854743]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XgAEPCFEx6U",
        "colab_type": "text"
      },
      "source": [
        "### Calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48gx6wQKSvoE",
        "outputId": "364ce683-9400-471d-c017-e2e695af6a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        if 1/(1+np.exp(-(np.dot(X[i],w)+b))) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "\n",
        "print(\"Train accuracy : \",1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(\"Test accuracy :\",1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy :  0.9541866666666666\n",
            "Test accuracy : 0.95256\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}